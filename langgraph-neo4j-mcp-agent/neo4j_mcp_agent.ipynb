{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-01",
   "metadata": {},
   "source": [
    "# LangGraph Neo4j MCP Agent\n",
    "\n",
    "This notebook demonstrates how to build a **ReAct agent** using LangGraph that connects to a Neo4j graph database via the Model Context Protocol (MCP).\n",
    "\n",
    "## Features\n",
    "\n",
    "- **LangGraph 1.0+**: Latest stable agent framework with caching and deferred nodes\n",
    "- **MCP Protocol**: Standardized tool integration using `langchain-mcp-adapters`\n",
    "- **Neo4j Integration**: Query graph databases using natural language\n",
    "- **AWS Bedrock**: Uses Claude models via the Bedrock Converse API\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. AWS credentials configured (IAM role in SageMaker or credentials file)\n",
    "2. Bedrock model access enabled for Claude\n",
    "3. MCP server endpoint URL and credentials\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-header-01",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "Install the required packages using `%pip` (recommended for SageMaker Studio notebooks).\n",
    "\n",
    "> **Note**: After installation, you must restart the kernel for changes to take effect."
   ]
  },
  {
   "cell_type": "code",
   "id": "install-packages-01",
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Install required packages for LangGraph Neo4j MCP Agent\n",
    "# Using %pip ensures packages install in the correct kernel environment\n",
    "\n",
    "%pip install --upgrade --quiet \\\n",
    "    langchain>=0.3.14 \\\n",
    "    langgraph>=0.2.60 \\\n",
    "    langchain-aws>=0.2.10 \\\n",
    "    langchain-mcp-adapters>=0.2.1 \\\n",
    "    mcp>=1.3.0 \\\n",
    "    httpx>=0.28.0 \\\n",
    "    boto3>=1.36.0 \\\n",
    "    nest-asyncio>=1.6.0\n",
    "\n",
    "print(\"Packages installed successfully!\")\n",
    "print(\"Please restart the kernel to load the new packages.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restart-header-01",
   "metadata": {},
   "source": [
    "## 2. Restart Kernel\n",
    "\n",
    "Run the cell below to restart the kernel after installing packages.\n",
    "\n",
    "> **Important**: After running this cell, wait for the kernel to restart, then continue from the next section."
   ]
  },
  {
   "cell_type": "code",
   "id": "restart-kernel-01",
   "metadata": {
    "tags": [
     "restart"
    ]
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Restart the kernel to load newly installed packages\n",
    "# This is required after pip install in SageMaker notebooks\n",
    "\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header-01",
   "metadata": {},
   "source": [
    "## 3. Import Libraries\n",
    "\n",
    "Import all required libraries after the kernel restart."
   ]
  },
  {
   "cell_type": "code",
   "id": "imports-01",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import httpx\n",
    "import nest_asyncio\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "# Enable nested asyncio for Jupyter notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "version-check-header-01",
   "metadata": {},
   "source": [
    "### Verify Package Versions\n",
    "\n",
    "Check that the installed packages meet the minimum version requirements."
   ]
  },
  {
   "cell_type": "code",
   "id": "version-check-01",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import importlib.metadata\n",
    "\n",
    "packages = [\n",
    "    \"langchain\",\n",
    "    \"langgraph\",\n",
    "    \"langchain-aws\",\n",
    "    \"langchain-mcp-adapters\",\n",
    "    \"mcp\",\n",
    "    \"httpx\",\n",
    "    \"boto3\",\n",
    "]\n",
    "\n",
    "print(\"Installed Package Versions:\")\n",
    "print(\"-\" * 40)\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        version = importlib.metadata.version(pkg)\n",
    "        print(f\"{pkg:25} {version}\")\n",
    "    except importlib.metadata.PackageNotFoundError:\n",
    "        print(f\"{pkg:25} NOT INSTALLED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header-01",
   "metadata": {},
   "source": [
    "## 4. Configuration\n",
    "\n",
    "Configure the agent settings including:\n",
    "- AWS region for Bedrock\n",
    "- Model ID (Claude Sonnet)\n",
    "- MCP server credentials"
   ]
  },
  {
   "cell_type": "code",
   "id": "config-01",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Configuration\nAWS_REGION = \"us-west-2\"  # Region for Bedrock\n\n# Use inference profile ARN from Bedrock IDE (required for SageMaker Unified Studio)\n# See MODEL.md for how to get this ARN\nINFERENCE_PROFILE_ARN = \"arn:aws:bedrock:us-west-2:159878781974:application-inference-profile/hsl5b7kh1279\"\n\n# MCP Server Configuration\n# Option 1: Load from credentials file\nCREDENTIALS_FILE = Path(\".mcp-credentials.json\")\n\n# Option 2: Set directly (uncomment and fill in)\n# MCP_GATEWAY_URL = \"https://your-gateway-url/mcp\"\n# MCP_ACCESS_TOKEN = \"your-access-token\"\n\nprint(f\"AWS Region: {AWS_REGION}\")\nprint(f\"Inference Profile: {INFERENCE_PROFILE_ARN}\")\nprint(f\"Credentials file: {CREDENTIALS_FILE}\")"
  },
  {
   "cell_type": "markdown",
   "id": "system-prompt-header-01",
   "metadata": {},
   "source": [
    "### System Prompt\n",
    "\n",
    "Define the system prompt that guides the agent's behavior when querying the Neo4j database."
   ]
  },
  {
   "cell_type": "code",
   "id": "system-prompt-01",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a helpful Neo4j database assistant with access to tools that let you query a Neo4j graph database.\n",
    "\n",
    "Your capabilities include:\n",
    "- Retrieve the database schema to understand node labels, relationship types, and properties\n",
    "- Execute read-only Cypher queries to answer questions about the data\n",
    "- Do not execute any write Cypher queries\n",
    "\n",
    "When answering questions about the database:\n",
    "1. First retrieve the schema to understand the database structure\n",
    "2. Formulate appropriate Cypher queries based on the actual schema\n",
    "3. If a query returns no results, explain what you looked for and suggest alternatives\n",
    "4. Format results in a clear, human-readable way\n",
    "5. Cite the actual data returned in your response\n",
    "\n",
    "Important Cypher notes:\n",
    "- Use MATCH patterns that align with the actual schema\n",
    "- For counting, use MATCH (n:Label) RETURN count(n)\n",
    "- For listing items, add LIMIT to avoid overwhelming results\n",
    "- Handle potential NULL values gracefully\n",
    "\n",
    "Be concise but thorough in your responses.\"\"\"\n",
    "\n",
    "print(\"System prompt configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "credentials-header-01",
   "metadata": {},
   "source": [
    "## 5. Credential Management\n",
    "\n",
    "Functions to load and refresh OAuth2 credentials for the MCP server."
   ]
  },
  {
   "cell_type": "code",
   "id": "credentials-01",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_credentials(credentials_file: Path = CREDENTIALS_FILE) -> dict:\n",
    "    \"\"\"\n",
    "    Load credentials from .mcp-credentials.json file.\n",
    "    \n",
    "    Expected format:\n",
    "    {\n",
    "        \"gateway_url\": \"https://...\",\n",
    "        \"access_token\": \"...\",\n",
    "        \"token_expires_at\": \"2025-01-21T12:00:00+00:00\",\n",
    "        \"token_url\": \"https://...\",\n",
    "        \"client_id\": \"...\",\n",
    "        \"client_secret\": \"...\",\n",
    "        \"scope\": \"...\",\n",
    "        \"region\": \"us-west-2\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    if not credentials_file.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Credentials file not found: {credentials_file}\\n\"\n",
    "            \"Create .mcp-credentials.json or set credentials directly in the config cell.\"\n",
    "        )\n",
    "    \n",
    "    with open(credentials_file) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def check_token_expiry(credentials: dict) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the token is expired or expiring within 5 minutes.\n",
    "    Returns True if token is still valid.\n",
    "    \"\"\"\n",
    "    expires_at_str = credentials.get(\"token_expires_at\")\n",
    "    if not expires_at_str:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        expires_at = datetime.fromisoformat(expires_at_str)\n",
    "        now = datetime.now(timezone.utc)\n",
    "        # 5 minute buffer\n",
    "        return now < (expires_at - timedelta(minutes=5))\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "\n",
    "def refresh_token(credentials: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Refresh the OAuth2 access token using client credentials flow.\n",
    "    Updates and saves the credentials file.\n",
    "    \"\"\"\n",
    "    token_url = credentials.get(\"token_url\")\n",
    "    client_id = credentials.get(\"client_id\")\n",
    "    client_secret = credentials.get(\"client_secret\")\n",
    "    scope = credentials.get(\"scope\", \"\")\n",
    "    \n",
    "    if not all([token_url, client_id, client_secret]):\n",
    "        raise ValueError(\n",
    "            \"Missing token refresh credentials (token_url, client_id, client_secret)\"\n",
    "        )\n",
    "    \n",
    "    print(\"Refreshing OAuth2 token...\")\n",
    "    \n",
    "    response = httpx.post(\n",
    "        token_url,\n",
    "        data={\n",
    "            \"grant_type\": \"client_credentials\",\n",
    "            \"client_id\": client_id,\n",
    "            \"client_secret\": client_secret,\n",
    "            \"scope\": scope,\n",
    "        },\n",
    "        headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n",
    "        timeout=30,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    token_data = response.json()\n",
    "    \n",
    "    # Calculate expiry time\n",
    "    expires_in = token_data.get(\"expires_in\", 3600)\n",
    "    expires_at = datetime.now(timezone.utc) + timedelta(seconds=expires_in)\n",
    "    \n",
    "    # Update credentials\n",
    "    credentials[\"access_token\"] = token_data[\"access_token\"]\n",
    "    credentials[\"token_expires_at\"] = expires_at.isoformat()\n",
    "    \n",
    "    # Save updated credentials\n",
    "    with open(CREDENTIALS_FILE, \"w\") as f:\n",
    "        json.dump(credentials, f, indent=2)\n",
    "    \n",
    "    print(f\"Token refreshed. New expiry: {expires_at.isoformat()}\")\n",
    "    return credentials\n",
    "\n",
    "\n",
    "print(\"Credential management functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-setup-header-01",
   "metadata": {},
   "source": [
    "## 6. Agent Setup\n",
    "\n",
    "Initialize the LLM and create the ReAct agent with MCP tools."
   ]
  },
  {
   "cell_type": "code",
   "id": "agent-setup-01",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from langchain_aws import ChatBedrockConverse\n\ndef get_llm(region: str = AWS_REGION, model_id: str = INFERENCE_PROFILE_ARN):\n    \"\"\"\n    Initialize the LLM using AWS Bedrock Converse API.\n    \"\"\"\n    return ChatBedrockConverse(\n        model=model_id,\n        provider=\"anthropic\",  # Required when using ARN\n        region_name=region,\n        temperature=0,\n    )\n\n\nasync def create_mcp_agent(gateway_url: str, access_token: str, region: str = AWS_REGION):\n    \"\"\"\n    Create a ReAct agent connected to the MCP server.\n    \n    Returns:\n        tuple: (agent, client, tools)\n    \"\"\"\n    print(f\"Connecting to MCP server: {gateway_url[:50]}...\")\n    \n    # Initialize MCP client\n    client = MultiServerMCPClient(\n        {\n            \"neo4j\": {\n                \"transport\": \"streamable_http\",\n                \"url\": gateway_url,\n                \"headers\": {\n                    \"Authorization\": f\"Bearer {access_token}\",\n                },\n            }\n        }\n    )\n    \n    # Get available tools\n    tools = await client.get_tools()\n    print(f\"Loaded {len(tools)} tools:\")\n    for tool in tools:\n        print(f\"  - {tool.name}\")\n    \n    # Initialize LLM\n    print(f\"\\nInitializing LLM (region: {region})...\")\n    llm = get_llm(region)\n    print(f\"Profile: {INFERENCE_PROFILE_ARN}\")\n    \n    # Create ReAct agent\n    print(\"\\nCreating ReAct agent...\")\n    agent = create_agent(llm, tools, system_prompt=SYSTEM_PROMPT)\n    print(\"Agent ready!\")\n    \n    return agent, client, tools\n\n\nprint(\"Agent setup functions defined.\")"
  },
  {
   "cell_type": "markdown",
   "id": "query-header-01",
   "metadata": {},
   "source": [
    "## 7. Query Functions\n",
    "\n",
    "Functions to run queries through the agent."
   ]
  },
  {
   "cell_type": "code",
   "id": "query-functions-01",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "async def ask_agent(agent, question: str, verbose: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Send a question to the agent and return the response.\n",
    "    \n",
    "    Args:\n",
    "        agent: The LangGraph agent\n",
    "        question: Natural language question\n",
    "        verbose: Print the question and answer\n",
    "    \n",
    "    Returns:\n",
    "        str: The agent's response\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Question: {question}\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "    \n",
    "    result = await agent.ainvoke({\"messages\": [(\"human\", question)]})\n",
    "    \n",
    "    # Extract the final response\n",
    "    messages = result.get(\"messages\", [])\n",
    "    if messages:\n",
    "        final_message = messages[-1]\n",
    "        content = getattr(final_message, \"content\", str(final_message))\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Answer:\")\n",
    "            print(\"-\" * 70)\n",
    "            print(content)\n",
    "            print(\"-\" * 70)\n",
    "        \n",
    "        return content\n",
    "    \n",
    "    return \"No response from agent\"\n",
    "\n",
    "\n",
    "print(\"Query functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "init-header-01",
   "metadata": {},
   "source": [
    "## 8. Initialize Agent\n",
    "\n",
    "Load credentials and create the agent instance."
   ]
  },
  {
   "cell_type": "code",
   "id": "init-agent-01",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load and validate credentials\n",
    "print(\"Loading credentials...\")\n",
    "credentials = load_credentials()\n",
    "\n",
    "# Auto-refresh token if expired\n",
    "if not check_token_expiry(credentials):\n",
    "    print(\"Token expired or expiring soon.\")\n",
    "    credentials = refresh_token(credentials)\n",
    "else:\n",
    "    print(f\"Token valid until: {credentials.get('token_expires_at')}\")\n",
    "\n",
    "gateway_url = credentials[\"gateway_url\"]\n",
    "access_token = credentials[\"access_token\"]\n",
    "region = credentials.get(\"region\", AWS_REGION)\n",
    "\n",
    "print(f\"\\nGateway: {gateway_url}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "create-agent-01",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the agent\n",
    "agent, mcp_client, tools = asyncio.get_event_loop().run_until_complete(\n",
    "    create_mcp_agent(gateway_url, access_token, region)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo-header-01",
   "metadata": {},
   "source": [
    "## 9. Demo Queries\n",
    "\n",
    "Run sample queries to test the agent."
   ]
  },
  {
   "cell_type": "code",
   "id": "demo-schema-01",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Query 1: Get database schema\n",
    "response = asyncio.get_event_loop().run_until_complete(\n",
    "    ask_agent(agent, \"What is the database schema? Give me a brief summary.\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "id": "demo-count-01",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Query 2: Count entities\n",
    "response = asyncio.get_event_loop().run_until_complete(\n",
    "    ask_agent(agent, \"How many nodes are in the database by label?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "id": "demo-explore-01",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Query 3: Explore relationships\n",
    "response = asyncio.get_event_loop().run_until_complete(\n",
    "    ask_agent(agent, \"What types of relationships exist in the database?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "custom-header-01",
   "metadata": {},
   "source": [
    "## 10. Custom Queries\n",
    "\n",
    "Run your own natural language queries against the Neo4j database."
   ]
  },
  {
   "cell_type": "code",
   "id": "custom-query-01",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Enter your custom question here\n",
    "CUSTOM_QUESTION = \"List 5 sample records from the most populated node type.\"\n",
    "\n",
    "response = asyncio.get_event_loop().run_until_complete(\n",
    "    ask_agent(agent, CUSTOM_QUESTION)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interactive-header-01",
   "metadata": {},
   "source": [
    "### Interactive Query Cell\n",
    "\n",
    "Use this cell to ask multiple questions interactively."
   ]
  },
  {
   "cell_type": "code",
   "id": "interactive-query-01",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Interactive query - modify the question and run this cell\n",
    "question = \"YOUR QUESTION HERE\"\n",
    "\n",
    "if question != \"YOUR QUESTION HERE\":\n",
    "    response = asyncio.get_event_loop().run_until_complete(\n",
    "        ask_agent(agent, question)\n",
    "    )\n",
    "else:\n",
    "    print(\"Replace 'YOUR QUESTION HERE' with your actual question and run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-header-01",
   "metadata": {},
   "source": [
    "## 11. Cleanup\n",
    "\n",
    "Clean up resources when done."
   ]
  },
  {
   "cell_type": "code",
   "id": "cleanup-01",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optional: Clear variables to free memory\n",
    "# del agent, mcp_client, tools, credentials\n",
    "\n",
    "print(\"Session complete.\")\n",
    "print(\"\\nTo continue querying, run the cells in Section 8-10.\")\n",
    "print(\"To reinstall packages, run Sections 1-2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resources-01",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [LangChain MCP Adapters](https://github.com/langchain-ai/langchain-mcp-adapters)\n",
    "- [Neo4j MCP Server](https://github.com/neo4j-contrib/mcp-neo4j)\n",
    "- [AWS Bedrock Documentation](https://docs.aws.amazon.com/bedrock/)\n",
    "- [Model Context Protocol](https://modelcontextprotocol.io/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "sagemaker": {
   "instance_type": "ml.t3.medium",
   "kernel_name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}