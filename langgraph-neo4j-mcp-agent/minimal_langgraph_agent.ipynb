{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-01",
   "metadata": {},
   "source": "# Minimal LangGraph Agent for SageMaker Studio\n\nA simple LangGraph agent using AWS Bedrock Claude.\n\n## Setup (Run from CLI before using this notebook)\n\n```bash\n./setup-inference-profile.sh sonnet\n```\n\nCopy the output ARN into `INFERENCE_PROFILE_ARN` in the next cell."
  },
  {
   "cell_type": "code",
   "id": "asqvbyrqcs",
   "source": "#################################################\n# CONFIGURATION\n# Use the profile created by Bedrock IDE (from SageMaker Unified Studio)\n#################################################\n\nINFERENCE_PROFILE_ARN = \"arn:aws:bedrock:us-west-2:159878781974:application-inference-profile/hsl5b7kh1279\"\nREGION = \"us-west-2\"\n\n#################################################",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import importlib.metadata\n",
    "\n",
    "packages = [\n",
    "    \"langchain\",\n",
    "    \"langchain-core\",\n",
    "    \"langgraph\",\n",
    "    \"langchain-aws\",\n",
    "    \"langchain-mcp-adapters\",\n",
    "    \"mcp\",\n",
    "    \"httpx\",\n",
    "    \"boto3\",\n",
    "]\n",
    "\n",
    "print(\"Pre-installed packages:\")\n",
    "print(\"-\" * 50)\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        version = importlib.metadata.version(pkg)\n",
    "        print(f\"{pkg:30} {version}\")\n",
    "    except importlib.metadata.PackageNotFoundError:\n",
    "        print(f\"{pkg:30} NOT INSTALLED\")"
   ],
   "id": "9e4c3dc65590a95b"
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "imports",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tools-header",
   "metadata": {},
   "source": [
    "## 3. Define Tools\n",
    "\n",
    "Simple tools for testing the agent's tool-calling capabilities."
   ]
  },
  {
   "cell_type": "code",
   "id": "tools",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current date and time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers together.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "tools = [get_current_time, add_numbers]\n",
    "print(f\"Defined {len(tools)} tools: {[t.name for t in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llm-header",
   "metadata": {},
   "source": "## 4. Initialize LLM\n\nUses the `INFERENCE_PROFILE_ARN` from the configuration cell above."
  },
  {
   "cell_type": "code",
   "id": "llm-setup",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Uses INFERENCE_PROFILE_ARN and REGION from the configuration cell above\n\nllm = ChatBedrockConverse(\n    model=INFERENCE_PROFILE_ARN,\n    provider=\"anthropic\",  # Required when using ARN\n    region_name=REGION,\n    temperature=0,\n)\n\n# Bind tools to the LLM\nllm_with_tools = llm.bind_tools(tools)\n\nprint(f\"LLM initialized!\")\nprint(f\"Profile: {INFERENCE_PROFILE_ARN}\")\nprint(f\"Region: {REGION}\")"
  },
  {
   "cell_type": "markdown",
   "id": "graph-header",
   "metadata": {},
   "source": [
    "## 5. Build the LangGraph Agent\n",
    "\n",
    "A minimal ReAct-style agent with:\n",
    "- `agent` node: calls the LLM\n",
    "- `tools` node: executes tools\n",
    "- Conditional edge: routes to tools or ends"
   ]
  },
  {
   "cell_type": "code",
   "id": "graph-build",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"Determine whether to continue to tools or end.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    \"\"\"Call the LLM.\"\"\"\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Build the graph\n",
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"agent\", call_model)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Add edges\n",
    "graph.add_edge(START, \"agent\")\n",
    "graph.add_conditional_edges(\"agent\", should_continue)\n",
    "graph.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "agent = graph.compile()\n",
    "\n",
    "print(\"Agent graph compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-header",
   "metadata": {},
   "source": [
    "## 6. Visualize the Graph (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "id": "visualize",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display the graph structure (requires graphviz)\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Graph visualization not available: {e}\")\n",
    "    print(\"\\nGraph structure:\")\n",
    "    print(\"  START -> agent -> (tools -> agent) | END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run-header",
   "metadata": {},
   "source": [
    "## 7. Run the Agent"
   ]
  },
  {
   "cell_type": "code",
   "id": "run-agent",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_agent(question: str):\n",
    "    \"\"\"Run the agent with a question and display the response.\"\"\"\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    result = agent.invoke({\n",
    "        \"messages\": [\n",
    "            SystemMessage(content=\"You are a helpful assistant. Use tools when needed.\"),\n",
    "            HumanMessage(content=question),\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    final_message = result[\"messages\"][-1]\n",
    "    print(f\"\\nResponse:\\n{final_message.content}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "id": "test-time",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test: Get current time\n",
    "result = run_agent(\"What is the current time?\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "test-math",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test: Math calculation\n",
    "result = run_agent(\"What is 42 + 17?\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "test-both",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test: Multiple tools\n",
    "result = run_agent(\"What time is it and what is 100 + 200?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "custom-header",
   "metadata": {},
   "source": [
    "## 8. Try Your Own Question"
   ]
  },
  {
   "cell_type": "code",
   "id": "custom-query",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Enter your own question here\n",
    "my_question = \"Add 999 and 1, then tell me the time.\"\n",
    "\n",
    "result = run_agent(my_question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
